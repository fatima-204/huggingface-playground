
# Hugging Face Basics

This repository contains basic experiments and explorations using Hugging Face pipelines, tokenizers, and pre-trained models. It serves as a beginner-friendly introduction to working with Hugging Face's `transformers` library for natural language processing (NLP) tasks.

## Features

- **Hugging Face Pipelines**: Quick and easy NLP tasks like text classification, sentiment analysis, and more.
- **Tokenizers**: Explore how tokenization works with Hugging Face's tokenizers.
- **Pre-trained Models**: Experiment with popular pre-trained models for various NLP tasks.

## Getting Started



 **Install Dependencies**:
   Install the required libraries using `pip`:
   ```bash
   pip install transformers datasets
   ```

 **Run the Code**:
   Open the Jupyter Notebook or Python scripts to explore Hugging Face pipelines, tokenizers, and models.

## Examples

- **Text Classification**: Use a pre-trained model to classify text.
- **Tokenization**: Understand how text is tokenized for model input.
- **Sentiment Analysis**: Analyze the sentiment of a given text.

## Resources

- [Hugging Face Documentation](https://huggingface.co/docs)
- [Transformers Library](https://github.com/huggingface/transformers)

